# 자동사고감지 및 알림시스템

## 서버
  서버는 라즈베리파이4에 리눅스 운영체제인 라즈비안OS를 설치하여 운영된다. 서버에서는 MySQL을 기반으로 한 오픈 소스 관계형 데이터베이스 관리 시스템 mariaDB를 적용하여 사고 데이터를 안전하게 저장한다. 사고 및 충격 발생 시, 사고 차량은 Application Server로 ID(사용자 전화번호), GPS정보(경도, 위도), 가속도값을 전송한다. 이러한 데이터는 Database에 저장된다. Database는 데이터를 안정적으로 저장하고 관리하기 위한 용도로 사용되며, 사용자가 데이터에 접근할 수 있는 인터페이스를 제공한다.

GPS 기반으로 근방 운전자의 스마트폰에 사고 알림 메시지를 전송하기 위해 서버에서는 GPS 정보를 수집하고 처리한다. 이를 위해 TCP/IP 통신방식을 사용하며, 서버에서는 TCP/IP 통신으로부터 받은 정보를 처리하여 근방 운전자의 스마트폰으로 사고 알림 메시지를 전송한다. 또한 서버에서는 안정적인 운영을 위해 정기적으로 백업을 수행하고, 서버에 접속하는 사용자들의 권한을 제한함으로써 보안성을 높이고 있다.<br>
![image](https://user-images.githubusercontent.com/124419697/236854186-10fd5cf6-8b33-415f-a334-b0bfcde2e972.png)
<br>
그림 TCP/IP 서버 클라이언트 구성<br><br>

## 차선 감지 시스템
차선감지시스템(Lane Departure Warning System, LDWS)은 차량이 주행 중에 차선을 이탈하거나, 차선 변경을 시도할 때 운전자에게 경고를 보내는 시스템이다. 이 시스템은 일반적으로 차량 전면 또는 후면에 장착된 카메라나 레이더 센서 등을 사용하여 차선의 위치를 감지하고, 차선 이탈 시 경고 신호를 발생시킨다.

LDWS는 시각적 또는 청각적인 경고를 발생시켜 운전자에게 주의를 주며, 일부 시스템은 핸들이나 운적석에 진동 등과 같은 물리적인 경고도 제공할 수 있다. 또한, 일부 차량에서는 차선 이탈 경고 시스템이 자동으로 핸들을 흔들거나 브레이크를 조작하여 차량의 방향을 조정하는 기능도 제공한다. 이러한 기능은 운전자의 부주의나 졸음 운전 등으로 인한 교통사고를 예방하고 운전 안전성을 향상시키는 데에 기여한다.

###1. 시스템 구성
  전체 시스템 구성은 데이터 수집 장치, 스마트폰 어플리케이션, 서버로 구성되며, 각각의 역할은 다음과 같다.

  데이터 수집 장치에서는 9축 센서를 사용하여 가속도 데이터를 측정하고, 가속도 크기를 계산하고 차량 데이터를 SD 카드에 저장한다. 이때, 충격값이 특정 임계값을 넘어가면 블루투스를 통해 스마트폰에 알림을 보낸다. 또한, Jetson Nano와 카메라를 사용하여 영상을 분석하고, 정상 상태, 측정 오류, 사고 상황 등을 2중으로 판단하는 데 사용된다.

데이터 수집 장치에서는 MCU(STM32H750)를 사용하여 다른 장치들과 통신한다. 9축 IMU 센서는 SPI, SD 카드는 SDIO, 차량은 CAN, 그리고 Jetson Nano, GPS, 블루투스 장치는 UART로 통신한다. Jetson Nano와 연결은 개발 단계에 있고 추후에 연결할 예정이다<br>
![image](https://user-images.githubusercontent.com/124419697/236854664-ffed9da4-21b6-4975-b007-4af8f0c9db4a.png)<br>

그림 사고 감지 장치 구성도<br><br>
차량 운전 중 가속도 센서에서 수집된 데이터를 분석하여, 차량의 가속도가 4G 이상인 경우 차량의 정보(전화번호, 날짜, 시간, 위도, 경도, 가속도)를 스마트폰에 전송한다. 스마트폰 어플리케이션에서는 수집된 데이터를 TCP/IP를 통해 서버로 전송한다. 사고 발생시 서버에서는 GPS기반으로 사고 발생 지점 약 400m의 모든 어플리케이션 차량에게 경고 메시지를 전송한다. 이를 통해 차량 주행 중 발생하는 사고를 빠르게 알려줌으로써 2차 사고를 예방할 수 있다. 

##순서도 /시스템 모식도
서버와 SQL 전용 클라이언트가 작동하고 있는 중에 사고감지장치에서 사고를 감지하면 블루투스를 통해 안드로이드로 정보를 전달한다. 스마트폰은 TCP/IP로 서버와 연결되어 있으며, GPS값과 가속도값을 전송한다. 가속도값에 따라서 사고로 인식하면 근방 약 400~500m의 사용자 앱에 알림을 보낸다.<br>
![image](https://user-images.githubusercontent.com/124419697/236854909-073f3a06-884a-4d4e-99cf-9bb6f618383c.png)<br>

그림 사고 감지 및 알림 알고리즘(빨간 사각형이 구현부분)
<br><br>
 시스템 테스트 및 결과
  사고 감지 장치를 차량에 부착하면, 사고 시에 측정되는 가속도값은 높기 때문에 평상시에는 측정하기 어렵다. 따라서 장치를 테스트하기 위해 장치를 분리하여 책상과 충돌하는 방식으로 충격을 가하였다. 충격값이 8G가 측정되었고 사고 감지되어 서버로 GPS값과 가속도 값을 전송하였다. 다음 그림은 DB에 저장된 GPS 값과 가속도의 크기값이다. <br>
![image](https://user-images.githubusercontent.com/124419697/236855235-8ec83675-75a1-4dbb-a600-474f7955a6ec.png)<br>
![image](https://user-images.githubusercontent.com/124419697/236855266-c025b279-c233-4236-a0a3-06647e5e6bf5.png)<br>
그림 사고 감지 시스템 개념 그림<br><br>
어플리케이션을 2대의 스마트폰에 추가로 설치하여 사고 발생시에 사고 알림메시지가 오는 것을 확인하였다. 다음 그림은 기본 어플리케이션 화면과 알림메시지가 나오는 화면이다.<br>
![image](https://user-images.githubusercontent.com/124419697/236855495-16ae57a2-86ee-4ef1-89af-a9fcccc4f1c7.png)<br><br>

##개발 환경 및 개발 도구 설명
<br>
### 라즈베리 파이(Raspberry Pi)<br>
![image](https://user-images.githubusercontent.com/124419697/236857646-eef22436-cf92-40fa-8814-77556aa4178b.png)<br><br>
라즈베리 파이는 영국의 라즈베리 파이 재단에서 개발한 싱글 보드 컴퓨터로서 저럼한 가격에도 높은 성능을 가지고 있어 임베디드 시스템 개발 보드로 범용성을 가지고 있다. 교육용으로 시작되었지만 현재는 IoT, 로봇, 미디어 센터 등 다양한 분야에서 사용되고 있다. 또한 다양한 프로그래밍 언어를 지원하며, 파이썬을 비롯한 다양한 개발 툴도 제공되어 개발자들이 쉽게 개발할 수 있다.<br>
![image](https://user-images.githubusercontent.com/124419697/236857745-ee76c68e-883c-4750-b22b-9444336fd461.png)<br>
그림 15 라즈베리 파이 4 터미널<br><br>
라즈베리 파이 터미널에서 명령어를 이용하여 다양한 작업을 수행할 수 있다. 파일 및 디렉토리 관리나 시스템 정보 확인, 네트워크 관리 명령어를 사용하여 터미널에서 작업을 수행하면서 발생하는 결과를 통해 실시간으로 확인할 수 있어 디버깅이나 작업 결과 확인 등에 매우 유용하다.

### OpenCV 및 Python
 
OpenCV는 영상처리하는 오픈 소스 라이브러리이다. 개발 속도를 올리기 위해 Python으로 개발을 진행한다.<br>
![image](https://user-images.githubusercontent.com/124419697/236858034-b57a7e13-9f2b-4714-9b2f-f3fe614578b0.png)<br>
[사진6] python코드
grayscale: 입력 이미지를 흑백 이미지로 변환한다.
canny: 입력 이미지에 캐니 엣지 검출을 적용한다.
gaussian_blur: 입력 이미지에 가우시안 블러를 적용한다.
region_of_interest: 입력 이미지에서 관심 영역을 선택한다.
draw_lines: 입력 이미지에 검출된 직선을 그린다.
hough_lines: 입력 이미지에 허프 변환을 적용하여 직선을 검출한다.
weighted_img: 입력 이미지와 원본 이미지를 합친다.
<br><br>

##영상 차선 인식 시스템
그림 4.2-a에서는 블랙박스 장치에 장착된 카메라로부터 전방 도로의 영상이 입력되었다. 이 영상을 전처리하기 위해 가우시안 블러(Gaussian Blur) 필터링을 적용하여 그림 4.2-b와 같이 흐림 효과를 적용한 후, 회색으로 변환하였다.

이후, 그림 4.2-c에서는 Canny Edge Detection 기법을 사용하여, 픽셀 간의 경계를 강조하여 영상에서 차선을 검출하였다. 이때, 사다리꼴 형태로 설정된 ROI(Region of Interest) 내에서만 검출하도록 설정하여, 주변 환경의 영향을 최소화하였다. 그림 4.2-d에서는 인식된 차선을 사다리꼴 형태로 추출한 후, 좌우 양쪽의 끝점을 기준으로 영역을 설정하여 차선을 판단할 수 있도록 전처리를 수행하였다.<br>
![image](https://user-images.githubusercontent.com/124419697/236858391-27d477b4-2276-4627-bd8e-9610c512bef0.png)<br>
이어서, 그림 4.2-e에서는 Hough Transform 알고리즘을 적용하여, 검출된 차선의 점들을 직선 형태로 인식하여 초록색 선으로 그려낸 후, 그림 4.2-f와 같이 원본 영상에 인식한 차선을 결합하여 출력하였다. 이를 통해 차선 인식이 성공적으로 이루어졌음을 확인할 수 있다.

개발 중에 다양한 문제점이 발생하였다.
초기에는 openCV c++로 차선 인식 코드를 작성했으나, jetson nano에서 c++의 버전이 맞지 않아 파이썬으로 변경하여 만들었다. 동영상 화질에 따라 차선 인식 범위가 달라지는 문제가 있는데 720p에 맞춰서 코드를 작성하였으나, 블랙박스의 화질이 달라지면 인식 범위가 변경되는 문제가 발생하였다. 이를 해결하기 위해 사다리꼴 범위를 다시 설정하여 양쪽 사이드를 인식할 수 있도록 테스트가 필요하다. 추가로, 범위 안의 잡음 제거와 차선 이탈 시 서버로 데이터를 전송하는 기능을 추가할 예정이다.<br>

차선 인식 결과<br>
[https://youtu.be/OS__DeUEmHs](https://youtu.be/aPC0S0Ph8_I)<br><br>
안드로이드_테스트<br>
https://youtu.be/lWsJT9awwlY<br><br>
python 차선인식 과정<br>
https://github.com/rltpwns95/carline.git<br>
공모전 자료들입니다.
https://drive.google.com/drive/folders/15uxKUJKbvsZfGwvdp-i79P7jU4AGwvsg?usp=share_link
